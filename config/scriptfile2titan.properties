# -- Base configuration --
faunus.graph.input.script.file=@INPUT_SCRIPT@
faunus.graph.input.format=com.thinkaurelius.faunus.formats.script.ScriptInputFormat
faunus.input.location=@INPUT@

# -- HBase --
faunus.graph.output.format=com.thinkaurelius.faunus.formats.titan.hbase.TitanHBaseOutputFormat
faunus.graph.output.titan.storage.backend=hbase
faunus.graph.output.titan.storage.hostname=@IP@
faunus.graph.output.titan.storage.port=2181
faunus.graph.output.titan.storage.tablename=@TABLE@

faunus.sideeffect.output.format=org.apache.hadoop.mapreduce.lib.output.TextOutputFormat
faunus.output.location=@OUTPUT@
faunus.output.location.overwrite=true

# -- Elasticsearch --
faunus.graph.output.titan.storage.index.search.backend=elasticsearch
faunus.graph.output.titan.storage.index.search.hostname=@ELASTIC_IP@
faunus.graph.output.titan.storage.index.search.index-name=@TABLE@
faunus.graph.output.titan.storage.index.search.client-only=true

# -- Settings the hbase time out to deal with table splits - could also be set in hbase-site --
hbase.rpc.timeout=240000

# -- Batch Loading Settings --
faunus.graph.output.titan.storage.batch-loading=true
faunus.graph.output.titan.infer-schema=false

# -- Will uncomment below for NPI vertex loading --
#faunus.graph.output.blueprints.script-file=@OUTPUT_SCRIPT@

#-- These are set based on https://github.com/thinkaurelius/titan/wiki/Bulk-Loading --
faunus.graph.output.titan.ids.block-size=250000
faunus.graph.output.titan.storage.idauthority-wait-time=200
faunus.graph.output.titan.storage.idauthority-retries=1000

# -- HBase related --
faunus.graph.output.titan.ids.renew-timeout=450000
faunus.graph.output.titan.ids.partition=true

#-- Typically the number of HBase region servers --
faunus.graph.output.titan.ids.num-partitions=3

#-- MapReduce Settings --
mapred.map.tasks.speculative.execution=false
mapred.reduce.tasks.speculative.execution=false
mapred.job.tracker=@JOBTRACKER_IP@:9001
mapred.max.split.size=20971520

# -- Adjust tasks number to your server power --
mapred.map.tasks=40
mapred.reduce.tasks=40
mapred.job.reuse.jvm.num.tasks=-1
mapred.map.child.java.opts=-Xmx4G -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps
mapred.reduce.child.java.opts=-Xmx4G -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps

# -- Settings mapred time out to deal with table splits --
mapred.task.timeout=5400000

# -- Compress both intermediate outputs and final --
mapred.output.compress=true
mapred.compress.map.output=true

# -- Increasing the number of failures --
mapred.max.tracker.failures=20
mapred.map.max.attempts=20

